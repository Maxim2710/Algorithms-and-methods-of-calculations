# Algorithms-and-methods-of-calculations
___
![first_page](auxiliary_resources/first_page.jpeg)

1. ***Метод Симпсона с контролем погрешности по формуле Рунге.***

**Метод Симпсона** - это численный метод интегрирования, который использует аппроксимацию подынтегральной функции квадратичными интерполяционными полиномами и формулу трапеций для вычисления интеграла на каждом интервале. Для контроля погрешности метода Симпсона обычно используется метод Рунге, который позволяет оценить точность вычислений.

:heavy_exclamation_mark: *Алгоритм:* 

+ Определите функцию, которую вы хотите интегрировать, и пределы интегрирования.

+ Разбейте интервал интегрирования на равные подинтервалы. Для метода Симпсона необходимо, чтобы количество подинтервалов было чётным.

+ Вычислите значения функции в узлах интегрирования. Узлы интегрирования - это концы каждого подинтервала и их середины.

+ Примените формулу Симпсона для каждого подинтервала и вычислите приближенное значение интеграла. Формула Симпсона для одного подинтервала [a, b]:

![photo1](auxiliary_resources/1.png)

+ Сложите все приближенные значения интегралов на каждом подинтервале, чтобы получить общее приближенное значение интеграла.

+ Проверьте выполнение условия останова. Обычно используется критерий Рунге. Для этого вычислите интеграл с использованием двойного числа подинтервалов (n) и вычислите интеграл с использованием вдвое большего числа подинтервалов (2n). 

+ Вычислите оценку погрешности методом Рунге по формуле:

![photo2](auxiliary_resources/2.png)

+ Если оценка погрешности меньше заданного порога или число итераций достигло максимального значения, завершите процесс. В противном случае увеличьте количество подинтервалов в два раза и повторите шаги с 3 по 7.

+ Верните полученное приближенное значение интеграла в качестве результата.

[Реализация метода Симпсона](laboratory_work1/task1/Simpson.go)

___

2. ***Метод Монте-Карло.***

**Метод Монте-Карло** - это численный метод, который использует случайные выборки для решения различных математических задач, таких как вычисление интегралов, решение уравнений и оценка вероятностей. 

:heavy_exclamation_mark: *Алгоритм:* 

+ Определите функцию, которую необходимо интегрировать, и интервалы, в которых вы хотите вычислить интеграл.

+ Определите геометрическую область, которая описывает функцию на выбранном интервале.

+ Генерируйте случайные точки внутри этой геометрической области.

+ Определите, сколько из сгенерированных точек попадает в область, описывающую функцию.

+ Вычислите отношение числа точек, попавших в область функции, к общему числу сгенерированных точек. Это отношение обычно обозначается как r.

+ Умножьте это отношение r на площадь геометрической области, чтобы получить приближенное значение интеграла функции.

+ Оцените погрешность результата. Чем больше точек было сгенерировано, тем более точным будет приближение. Один из способов оценки погрешности - использование стандартного отклонения значений, полученных из множества случайных выборок.

+ Повторите шаги с 3 по 7 необходимое количество раз, чтобы получить удовлетворительную точность или погрешность.

+ Верните полученное приближенное значение интеграла в качестве результата.

[Реализация метода Монте-Карло](laboratory_work1/task2/MonteKarlo.go)
___
3. ***Адаптивный метод с использованием метода Симпсона.***

**Адаптивный метод Симпсона** - это численный метод интегрирования, который основан на методе Симпсона, но в отличие от обычного метода, он адаптивно подстраивает количество интервалов интегрирования для достижения заданной точности

:heavy_exclamation_mark: *Алгоритм:*

+ Начните с инициализации списка или стека, содержащего начальные интервалы интегрирования. Начальные интервалы могут быть выбраны произвольно или на основе какого-то заранее заданного разбиения области интегрирования.

+ Пока список интервалов не пуст:

  + Извлеките интервал из списка.
  + Разделите интервал пополам, получив два новых подинтервала.
  + Вычислите приближенное значение интеграла на каждом из подинтервалов, используя метод Симпсона.
  + Оцените погрешность интеграла на каждом подинтервале. Это может быть сделано, например, с помощью правила Рунге.
  + *Если оценка погрешности на подинтервалах удовлетворяет заданному критерию точности:*
    + Добавьте значения интегралов на каждом подинтервале к общему значению интеграла.
  + *Иначе:*
    + Добавьте оба подинтервала в список для дальнейшего исследования.
+ После завершения обработки всех интервалов верните общее значение интеграла как результат.

[Реализация адаптивного метода Симпсона](laboratory_work1/task3/AdaptiveSimpson.go)
___
4. ***Метод Гаусса-Жордана.***

**Метод Гаусса-Жордана** - это численный метод решения систем линейных алгебраических уравнений путем приведения матрицы системы к диагональному виду.

:heavy_exclamation_mark: *Алгоритм:*

+ Начните с инициализации матрицы системы линейных уравнений размера n×(n+1), где n - количество неизвестных. В этой матрице последний столбец будет содержать значения свободных членов системы.

+ Примените элементарные преобразования строк к матрице с целью приведения ее к треугольному виду. Элементарные преобразования строк включают в себя:

  + Деление строки на число.
  + Прибавление к одной строке другой строке, умноженной на число.
  + Перестановку двух строк.
+ После приведения матрицы к треугольному виду, начните обратный ход метода Гаусса-Жордана. Для этого начните с последнего уравнения и поочередно избавляйтесь от неизвестных, начиная с последней.

+ Для каждой строки, начиная с последней и заканчивая первой:

  + Избавьтесь от текущей неизвестной, выражая ее через уже найденные неизвестные и коэффициенты из соответствующей строки исходной матрицы.
  + После избавления от всех неизвестных текущей строки, переходите к следующей строке.
+ После завершения обратного хода, матрица примет диагональный вид, где на диагонали будут стоять коэффициенты для неизвестных.

+ Произведите нормализацию строк путем деления каждого элемента строки на соответствующий диагональный элемент.

+ Теперь матрица примет вид единичной матрицы, а в последнем столбце будет содержаться решение системы.

+ Верните значения в последнем столбце как решение системы линейных уравнений.

[Реализация метода Гаусса-Жордана](laboratory_work2/task1/GaussJordan.go)
___

5. ***Итерационный метод Зейделя.***

**Итерационный метод Зейделя** - это численный метод решения систем линейных алгебраических уравнений, который использует последовательные итерации для приближенного нахождения решения.

:heavy_exclamation_mark: *Алгоритм:*

+ Начните с инициализации начального приближения решения системы линейных уравнений. Обычно начальное приближение выбираются произвольно, но близкими к действительному решению.

+ Разбейте систему линейных уравнений на две части: верхнетреугольную и нижнетреугольную. Это можно сделать путем разделения матрицы коэффициентов системы на верхнюю и нижнюю треугольные матрицы.

+ Начните итерационный процесс:

  + Для каждого уравнения системы:
    + Используя текущее приближение для всех остальных неизвестных, вычислите новое приближение для текущей неизвестной.
    + Для вычисления нового приближения используйте уже вычисленные значения для неизвестных из текущей итерации.
    
+ После обновления всех неизвестных проведите проверку на достижение критерия останова:

  + Проверьте, насколько новые приближения отличаются от предыдущих. Если разница между старыми и новыми значениями не превышает заранее заданной точности, то процесс считается завершенным.
  + Если точность не достигнута, повторите итерационный процесс.
+ После достижения критерия останова верните значения неизвестных как решение системы линейных уравнений.

[Реализация итерационного метода Зейделя](laboratory_work2/task2/SeidelMethod.go)
___
6. ***Метод сопряженных направлений Флетчера-Ривса.***

Метод сопряженных направлений Флетчера-Ривса - это итерационный метод оптимизации для поиска минимума (или максимума) функции нескольких переменных. Он широко используется в численной оптимизации.

:heavy_exclamation_mark: *Алгоритм:*

+ Инициализация:

  + Задать начальную точку x_0 в пространстве поиска.
  + Выбрать начальное направление поиска d_0, например, градиент функции в точке x_0.
  + Задать критерий останова (например, достижение определенной точности или количество итераций).

+ Итерационный процесс:

  + Повторять следующие шаги, пока не будет достигнут критерий останова:
  + Вычислить оптимальную длину шага alpha_k в направлении d_k с помощью одномерной оптимизации.
  + Обновить текущую точку x_k: x_{k+1} = x_k + alpha_k * d_k.
  + Вычислить градиент функции в новой точке x_{k+1}.
  +Вычислить сопряженное направление d_{k+1}: d_{k+1} = -gradient f(x_{k+1}) + beta_k * d_k, где beta_k выбирается, например, по методу Полака-Рибьера.
  + Перейти к следующей итерации, увеличивая k на 1.

+ Завершение:

  + Вернуть последнее найденное значение x_{k+1} в качестве приближенного оптимального решения.

[Реализация метода сопряженных направлений Флетчера-Ривса](laboratory_work2/task3/FletcherReeves.go)
___
7. ***Метод Дихотомии.***

**Метод дихотомии**, также известный как метод деления отрезка пополам, - это численный метод для нахождения приближенного значения корня уравнения на заданном отрезке. Он основан на принципе замены отрезка на подотрезки, содержащие корень.

:heavy_exclamation_mark: *Алгоритм:*

+ Инициализация:

  + Задать начальный интервал [a,b], в котором предполагается нахождение корня уравнения.
  + Задать точность ε, которая определяет, насколько близко должно быть найденное значение к действительному корню.

+ Итерационный процесс:

  + Пока длина текущего интервала [a,b] больше точности ε:
    + Вычислить середину интервала: c=(a+b)/2.
    + Вычислить значения функции в точках a, b и c.
    + Определить, в какой половине интервала находится корень уравнения:
      + Если значение функции в точке a и c имеют одинаковый знак, значит корень находится в интервале [c,b].
      + Если значение функции в точке b и c имеют одинаковый знак, значит корень находится в интервале [a,c].
      + Если значение функции в точке c равно нулю (с учетом погрешности), то точка c является корнем, завершить алгоритм.
    + Уменьшить интервал поиска до нового интервала с корнем, например:
      + Если корень находится в интервале [c,b], обновить значение a=c.
      + Если корень находится в интервале [a,c], обновить значение b=c.

+ Завершение:

  + Вернуть значение c как найденное приближенное значение корня уравнения.

[Реализация метода Дихотомии](laboratory_work3/task1/Dichotomy.go)
___
8. ***Метод Ньютона.***

Метод Ньютона, также известный как метод касательных или метод касательных касательных, является численным методом для приближенного решения уравнений f(x)=0

:heavy_exclamation_mark: *Алгоритм:*

+ Инициализация:
    - Задать начальное приближение x_0 для корня уравнения.
    - Задать точность ε, которая определяет критерий останова итерационного процесса.
    - Задать максимальное количество итераций для предотвращения зацикливания.

+ Итерационный процесс:
    - Повторять следующие шаги, пока не будет выполнен критерий останова:
        + Вычислить значение функции f(x_k) и ее производной f'(x_k) в текущей точке x_k.
        + Вычислить приращение Δx_k = -f(x_k) / f'(x_k).
        + Обновить текущее приближение: x_{k+1} = x_k + Δx_k.
        + Проверить критерий останова:
            - Если |Δx_k| < ε, где ε - заданная точность, завершить итерационный процесс.
            - Если было выполнено максимальное количество итераций, завершить итерационный процесс.

+ Завершение:
    - Вернуть значение x_{k+1} как приближенное значение корня уравнения.

[Реализация метода Ньютона](laboratory_work3/task2/Newton.go)
___
9. ***Решение СНАУ методом Ньютона-Рафсона.***

**Метод Ньютона-Рафсона** - это численный метод для нахождения корня уравнения, который является модификацией метода Ньютона. Он также известен как метод касательных второго порядка. В отличие от метода Ньютона, метод Ньютона-Рафсона использует для вычисления приращения не только первую производную функции (градиент), но и вторую производную (гессиан), что позволяет улучшить скорость сходимости метода.

:heavy_exclamation_mark: *Алгоритм:*

<h4>Инициализация:</h4>
<ul>
    <li>Задать начальное приближение <em>x<sub>0</sub></em> для корня уравнения.</li>
    <li>Задать точность <em>ε</em>, которая определяет критерий останова итерационного процесса.</li>
    <li>Задать максимальное количество итераций для предотвращения зацикливания.</li>
</ul>

<h4>Итерационный процесс:</h4>
<p>Повторять следующие шаги, пока не будет выполнен критерий останова:</p>
<ul>
    <li>Вычислить значение функции <em>f(x<sub>k</sub>)</em> и ее производной <em>f'(x<sub>k</sub>)</em> в текущей точке <em>x<sub>k</sub></em>.</li>
    <li>Вычислить приращение <em>Δx<sub>k</sub> = -f(x<sub>k</sub>)/f'(x<sub>k</sub>)</em>.</li>
    <li>Обновить текущее приближение: <em>x<sub>k+1</sub> = x<sub>k</sub> + Δx<sub>k</sub></em>.</li>
    <li>Проверить критерий останова:</li>
    <ul>
        <li>Если <em>|Δx<sub>k</sub>| &lt; ε</em>, где <em>ε</em> - заданная точность, завершить итерационный процесс.</li>
        <li>Если было выполнено максимальное количество итераций, завершить итерационный процесс.</li>
    </ul>
</ul>

<h4>Завершение:</h4>
<p>Вернуть значение <em>x<sub>k+1</sub></em> как приближенное значение корня уравнения.</p>

[Реализация метода Ньютона-Рафсона](laboratory_work3/task3/NewtonRaphson.go)
___
10. ***Обратная квадратичная интерполяция для поиска минимума функции.***

**Обратная квадратичная интерполяция** - это численный метод для нахождения минимума функции одной переменной. Этот метод основан на интерполяции значений функции вокруг предполагаемого минимума, используя квадратичную функцию, а затем нахождении вершины параболы, которая является предполагаемым минимумом функции. Этот процесс повторяется до тех пор, пока не будет достигнута заданная точность или предельное количество итераций.

:heavy_exclamation_mark: *Алгоритм:*

<ol>
  <li><strong>Инициализация</strong>:
    <ul>
      <li>Выбрать три начальные точки <em>x<sub>0</sub></em>, <em>x<sub>1</sub></em>, <em>x<sub>2</sub></em> такие, что <em>x<sub>0</sub></em> &lt; <em>x<sub>1</sub></em> &lt; <em>x<sub>2</sub></em>.</li>
      <li>Определить значения функции <em>f(x<sub>0</sub>)</em>, <em>f(x<sub>1</sub>)</em>, <em>f(x<sub>2</sub>)</em> в этих точках.</li>
    </ul>
  </li>
  <li><strong>Итерационный процесс</strong>:
    <ul>
      <li>Повторять следующие шаги до достижения критерия останова:</li>
      <ol>
        <li>Выполнить обратную квадратичную интерполяцию для вычисления приближенного минимума функции. Для этого:
          <ul>
            <li>Найти квадратичную функцию <em>q(x)</em>, проходящую через три точки <em>(x<sub>0</sub>, f(x<sub>0</sub>))</em>, <em>(x<sub>1</sub>, f(x<sub>1</sub>))</em>, <em>(x<sub>2</sub>, f(x<sub>2</sub>))</em>.</li>
            <li>Найти вершину параболы <em>q(x)</em>, которая предположительно является минимумом функции. Это можно сделать аналитически, взяв производную <em>q'(x)</em> и приравняв ее к нулю.</li>
            <li>Обозначить найденную точку как <em>x<sub>new</sub></em>.</li>
          </ul>
        </li>
        <li>Вычислить значение функции в новой точке <em>f(x<sub>new</sub>)</em>.</li>
        <li>Обновить значения точек <em>x<sub>0</sub></em>, <em>x<sub>1</sub></em>, <em>x<sub>2</sub></em> в зависимости от их относительного положения и значений функции:
          <ul>
            <li>Если <em>f(x<sub>new</sub>)</em> &lt; <em>f(x<sub>1</sub>)</em>, то выбрать <em>x<sub>new</sub></em> в качестве новой точки <em>x<sub>2</sub></em>.</li>
            <li>Если <em>f(x<sub>new</sub>)</em> ≥ <em>f(x<sub>1</sub>)</em>:</li>
            <ul>
              <li>Если <em>x<sub>new</sub></em> лежит между <em>x<sub>1</sub></em> и <em>x<sub>2</sub></em>, то выбрать <em>x<sub>new</sub></em> в качестве новой точки <em>x<sub>0</sub></em>, а <em>x<sub>1</sub></em> стать новой точкой <em>x<sub>2</sub></em>.</li>
              <li>Если <em>x<sub>new</sub></em> лежит вне интервала между <em>x<sub>1</sub></em> и <em>x<sub>2</sub></em>, то выбрать <em>x<sub>new</sub></em> в качестве новой точки <em>x<sub>0</sub></em>, а <em>x<sub>2</sub></em> стать новой точкой <em>x<sub>1</sub></em>.</li>
            </ul>
          </ul>
        </li>
        <li>Проверить критерий останова:
          <ul>
            <li>Если достигнута заданная точность или выполнено максимальное количество итераций, завершить процесс.</li>
          </ul>
        </li>
      </ol>
    </ul>
  </li>
  <li><strong>Завершение</strong>:
    <ul>
      <li>Вернуть последнюю найденную точку <em>x<sub>new</sub></em> в качестве приближенного минимума функции.</li>
    </ul>
  </li>
</ol>

[Реализация обратной квадратичной интерполяции для поиска минимума функции](laboratory_work3/task4/InverseQuadraticInterpolation.go)
___
11. ***Полином Лагранжа.***

***Полином Лагранжа*** - это метод интерполяции, который используется для аппроксимации функции по набору известных точек. Этот алгоритм создает полином, который проходит через все заданные точки данных.

:heavy_exclamation_mark: *Алгоритм:*

<ol>
    <li><strong>Подготовка данных:</strong>
        <ul>
            <li>Получить набор известных точек данных, которые требуется интерполировать.</li>
            <li>Обозначить количество точек данных как <code>n</code>.</li>
        </ul>
    </li>
    <li><strong>Вычисление базисных полиномов:</strong>
        <ul>
            <li>Для каждой точки данных <code>x[i]</code> создать базисный полином <code>L[i](x)</code>, который равен 1 в точке <code>x[i]</code> и 0 в остальных точках.</li>
            <li>Формула базисного полинома Лагранжа: <img src="https://latex.codecogs.com/svg.latex?L_i%28x%29%20%3D%20%5Cprod_%7Bj%3D0%2C%20j%5Cneq%20i%7D%5E%7Bn%7D%20%5Cfrac%7Bx%20-%20x_j%7D%7Bx_i%20-%20x_j%7D" alt="Формула базисного полинома">.</li>
        </ul>
    </li>
    <li><strong>Построение полинома Лагранжа:</strong>
        <ul>
            <li>Для каждой точки данных <code>x[i]</code>, умножьте соответствующий базисный полином <code>L[i](x)</code> на значение <code>y[i]</code>, соответствующее этой точке.</li>
            <li>Сложите все полученные произведения.</li>
            <li>Полученная сумма и будет полиномом Лагранжа.</li>
        </ul>
    </li>
    <li><strong>Результат:</strong>
        <ul>
            <li>Полученный полином Лагранжа будет аппроксимировать исходную функцию, проходя через все заданные точки данных.</li>
        </ul>
    </li>
</ol>

[Реализация метода полинома Лагранжа](laboratory_work4/task1/LagrangeInterpolation.go)
___
12. ***Кубический сплайн.***

**Алгоритм кубического сплайна** — это метод интерполяции, который используется для аппроксимации набора данных гладкой кривой, состоящей из кусочно-кубических полиномов. Этот метод обеспечивает непрерывность первых двух производных на всем интервале данных, что делает его особенно полезным для моделирования гладких функций.

:heavy_exclamation_mark: *Алгоритм:*
    <ol>
        <li><strong>Ввод данных:</strong> Получаем набор данных в виде точек (x_i, y_i), где i = 0, 1, ..., n, отсортированных в порядке возрастания x.</li>
        <li><strong>Вычисление первых производных:</strong> Находим первые производные в каждой точке. Это можно сделать, например, с помощью метода конечных разностей или метода наименьших квадратов.</li>
        <li><strong>Вычисление вторых производных:</strong> Далее вычисляем вторые производные в каждой точке. Это можно сделать решив систему линейных уравнений, которая обычно строится с использованием сплайн-условий.</li>
        <li><strong>Конструирование кубических полиномов:</strong> Строим кубические полиномы для каждого интервала между точками данных, используя найденные первые и вторые производные.</li>
        <li><strong>Обеспечение непрерывности производных:</strong> Гарантируем непрерывность первых и вторых производных в точках сочленения.</li>
        <li><strong>Интерполяция:</strong> Используем построенные кубические полиномы для интерполяции значений внутри каждого интервала.</li>
    </ol>

[Реализация кубического сплайна](laboratory_work4/task2/CubicSpline.go)
___
13. ***Сплайн Эрмита.***

**Сплайн Эрмита** представляет собой кусочно-кубическую кривую, которая проходит через набор точек и учитывает значения производных в этих точках.</p>

:heavy_exclamation_mark: *Алгоритм:*
    <ol>
        <li><strong>Ввод данных:</strong> Получаем набор данных в виде точек (x_i, y_i) и значений производных в этих точках (dy/dx)_i, где i = 0, 1, ..., n, отсортированных в порядке возрастания x.</li>
        <li><strong>Конструирование интерполяционных полиномов:</strong> Для каждого сегмента между соседними точками строим кубический полином, используя формулы Эрмита.</li>
        <li><strong>Обеспечение непрерывности:</strong> Гарантируем непрерывность кривой и ее производных в узлах сочленения.</li>
        <li><strong>Интерполяция значений:</strong> Используем построенные полиномы для интерполяции значений внутри каждого сегмента.</li>
    </ol>

[Реализация сплайна Эрмита](laboratory_work4/task3/HermiteSpline.go)
___
14. ***Кривые Безье.***

**Кривые Безье** являются одним из наиболее популярных методов для описания плавных кривых в компьютерной графике и дизайне. Они могут быть использованы для создания кривых различных форм и сложности.

:heavy_exclamation_mark: *Алгоритм:*
    <ol>
        <li><strong>Определение контрольных точек:</strong> Задаем начальные и конечные точки кривой, а также промежуточные контрольные точки, определяющие форму кривой.</li>
        <li><strong>Выбор степени кривой:</strong> Определяем степень кривой, которая зависит от количества контрольных точек. Для кривых Безье используются кривые первого, второго, третьего и более высоких порядков.</li>
        <li><strong>Вычисление кривой Безье:</strong> Для каждой параметрической координаты t в интервале от 0 до 1 вычисляем координату кривой Безье с помощью соответствующего уравнения для каждой степени кривой.</li>
    </ol>

[Реализация кривых Безье](laboratory_work4/task4/BezierCurve.go)
___
15. ***Устойчивый алгоритм численного дифференцирования.***

**Численное дифференцирование** - это метод вычисления производных функций по значениям функции в наборе точек. Устойчивый алгоритм численного дифференцирования важен для избегания ошибок, связанных с потерей точности или нестабильностью при вычислениях.

:heavy_exclamation_mark: *Алгоритм:*
    <ol>
        <li><strong>Выбор метода дифференцирования:</strong> Выбираем метод численного дифференцирования, такой как метод конечных разностей или методы, основанные на интерполяции, в зависимости от требований задачи и характера данных.</li>
        <li><strong>Выбор шага дифференцирования:</strong> Определяем оптимальный шаг дифференцирования, который обеспечивает достаточную точность при вычислении производных. Этот шаг должен быть достаточно малым, чтобы минимизировать ошибки численного приближения, но при этом достаточно большим, чтобы избежать потери точности из-за вычислительных ошибок.</li>
        <li><strong>Применение выбранного метода:</strong> Применяем выбранный метод дифференцирования к заданным данным, вычисляя производные функции для каждой точки.</li>
        <li><strong>Обработка граничных условий:</strong> Обрабатываем граничные условия, если они присутствуют, чтобы обеспечить правильное вычисление производных на краях интервала.</li>
        <li><strong>Проверка стабильности:</strong> Проверяем стабильность алгоритма, убеждаясь, что вычисленные производные не содержат артефактов или нефизических значений.</li>
    </ol>

[Реализация устойчивого алгоритма численного дифференцирования](laboratory_work4/task5/Differentiate.go)